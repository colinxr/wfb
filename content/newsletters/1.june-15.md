---
title: 'June 15 | A Storefront for the Robots'
slug: 'june-15-seo-robot-hell'
---

## A Storefront for the Roboots | The Verge

"The SEO arms race has left Google and the web drowning in garbage text, with customers and businesses flailing to find each other."

I tend to cringe whenever clients talk about SEO. It's not that it isn't important. It's just one of the least humane parts of making things for the internet.

This story from Mia Sato at the Verge is fascinating and really sums up the long-term impact SEO has had digital content creators.

++ [A Storefront for the Roboots | The Verge ](https://www.theverge.com/23753963/google-seo-shopify-small-business-ai)

### Also from the Verge -- [Google is getting a lot worse because of the Reddit Blackouts](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests)

## "Just as we’ve strewn the oceans with plastic trash and filled the atmosphere with carbon dioxide, so we’re about to fill the Internet with blah."

As AI generated content fills up the online space, whether to produce SEO-ified product descriptions (see above), or public apologies, existing models will run out of human made data from which to learn.

Researchers in the UK and Canada have concluded that “learning from data produced by other models causes model collapse — a degenerative process whereby, over time, models forget the true underlying data distribution … this process is inevitable, even for cases with almost ideal conditions for long-term learning.”

The problem is illustrated "through a hypothetical scenario, wherein a machine learning model is trained on a dataset with pictures of 100 cats — 10 of them with blue fur, and 90 with yellow. The model learns that yellow cats are more prevalent, but also represents blue cats as more yellowish than they really are, returning some green-cat results when asked to produce new data. Over time, the original trait of blue fur erodes through successive training cycles, turning from blue to greenish, and ultimately yellow.

"This progressive distortion and eventual loss of minority data characteristics is model collapse. To prevent this, it’s important to ensure fair representation of minority groups in datasets, in terms of both quantity and accurate portrayal of distinctive features. The task is challenging due to models’ difficulty learning from rare events."

++ [The AI feedback loop: Researchers warn of ‘model collapse’ as AI trains on AI-generated content](https://venturebeat.com/ai/the-ai-feedback-loop-researchers-warn-of-model-collapse-as-ai-trains-on-ai-generated-content/)
