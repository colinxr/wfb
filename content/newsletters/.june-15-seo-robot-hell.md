---
title: 'A Storefront for the Robots'
date: 'June 15, 2023'
slug: 'june-15-seo-robot-hell'
---

## 1. A Storefront for the Robots | The Verge

"The SEO arms race has left Google and the web drowning in garbage text, with customers and businesses flailing to find each other."

I tend to cringe whenever clients talk about SEO. It's not that it isn't important. It's just one of the least humane parts of making things for the internet.

This story from Mia Sato at the Verge is fascinating and really sums up the long-term impact SEO has had digital content creators.

++ [A Storefront for the Roboots | The Verge ](https://www.theverge.com/23753963/google-seo-shopify-small-business-ai)

**_ Also from the Verge: [Google is getting a lot worse because of the Reddit Blackouts](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) _**

## 2. "Just as we’ve strewn the oceans with plastic trash and filled the atmosphere with carbon dioxide, so we’re about to fill the Internet with blah."

As AI generated content fills up the online space, whether to produce SEO-ified product descriptions (see above), or public apologies, existing models will run out of human made data from which to learn.

Researchers in the UK and Canada have concluded that "learning from data produced by other models causes model collapse — a degenerative process whereby, over time, models forget the true underlying data distribution." AI models will eventually forget the real information on which they were built.

Think of the situation where a learning model is trained on collection of 100 pictures of cats, 90 of them have yellow fur and 10 of them have blue fur. "The model learns that yellow cats are more prevalent, but also represents blue cats as more yellowish than they really are, returning some green-cat results when asked to produce new data. Over time, the original trait of blue fur erodes through successive training cycles, turning from blue to greenish, and ultimately yellow."

Over time, the original trait of blue fur is forgotten and replaced by greenish fur, and, finally, yellow fur. This is model collapse, a progressive optimization away from the truth of the matter.

AI struggles to deal with rare events, the researchess say. This then leads to "the progressive distortion and eventually loss" of minority traits in a dataset.

The researchers are concerned with preventing model collapse, but avoid the broader ramifications on culture as a whole. As AI grows it will naturally select for features from the majority.

Culturally, we've made massive strides in recent years in terms of representation and lifting up diverse voices and perspectives. We must fight to make sure the coming wave of AI does not undo this.

++ [The AI feedback loop: Researchers warn of ‘model collapse’ as AI trains on AI-generated content](https://venturebeat.com/ai/the-ai-feedback-loop-researchers-warn-of-model-collapse-as-ai-trains-on-ai-generated-content/)
